{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec  3 12:10:13 2019\n",
    "\n",
    "@author: SWH\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 경고 무시하는 코드\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "try:\n",
    "    from tensorflow.python.util import module_wrapper as deprecation\n",
    "except ImportError:\n",
    "    from tensorflow.python.util import deprecation_wrapper as deprecation\n",
    "deprecation._PER_MODULE_WARNING_LIMIT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "import os,random\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmath\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open('RML2016.10a_dict.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    Xd = u.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input(\"<choice the vectors. a: IQ, b: phase_amp, c: FFT >\") # 분류할 벡터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs, mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
    "\n",
    "X = []  \n",
    "lbl = []\n",
    "for mod in mods:\n",
    "    for snr in snrs:\n",
    "        X.append(Xd[(mod,snr)])\n",
    "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.vstack(X) # iq 벡터 데이터 저장 \n",
    "\n",
    "x_all = x_all.swapaxes(2, 1) # cnn의 input으로 넣기 위해 축 변환\n",
    "\n",
    "x_all = np.array(x_all)\n",
    "\n",
    "x_r = x_all[:,:,0] # real 분리\n",
    "x_i = x_all[:,:,1] # imagine 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_flat = np.ravel(x_r, order='c') # phase vector를 계산하기 위해 1차원으로 폄\n",
    "x_i_flat = np.ravel(x_i, order='c') # phase vector를 계산하기 위해 1차원으로 폄\n",
    "x_phase = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"waiting...\")\n",
    "for i in range(len(x_i_flat)):\n",
    "    x_phase.append(cmath.atan(x_r_flat[i]/x_i_flat[i])) # phase vector 계산\n",
    "\n",
    "print(\"done.\")    \n",
    "x_phase = np.array(x_phase)\n",
    "\n",
    "x_phase = x_phase.reshape(220000,128) \n",
    "x_amp = (x_r**2+x_i**2)**1/2 # amplitude vector 계산\n",
    "\n",
    "x_fft_r = np.fft.fft(x_r) # fft vector 계산\n",
    "x_fft_i = np.fft.fft(x_i) # fft vector 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_phase_amp = np.dstack((x_phase, x_amp)) # phase와 amplitude vector 합침\n",
    "x_fft = np.dstack((x_fft_r, x_fft_i)) # FFT vector 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777) # 랜덤으로 train을 뽑을 거기때문에 랜덤 시드 고정\n",
    "n_examples = x_all.shape[0] # 총 데이터 갯수\n",
    "n_train = n_examples * 0.67 # 67%만큼 train에 사용\n",
    "train_idx = np.random.choice(220000, size=int(n_train), replace=False) # 전체에서 67%만큼 train index 뽑음\n",
    "test_idx = list(set(range(0,n_examples))-set(train_idx)) # 전체에서 train 뽑은 나머지 (33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a b c 선택시 분류에 사용할 vector가 달라짐\n",
    "if data == 'a': \n",
    "    x_train = x_all[train_idx]\n",
    "    x_test =  x_all[test_idx]\n",
    "    print(\"IQ vector selected.\")\n",
    "if data == 'b':\n",
    "    x_train = x_phase_amp[train_idx]\n",
    "    x_test =  x_phase_amp[test_idx]\n",
    "    print(\"phase and amp vector selected.\")\n",
    "if data == 'c':\n",
    "    x_train = x_fft[train_idx]\n",
    "    x_test =  x_fft[test_idx]\n",
    "    print(\"FFT vector selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\n",
    "y_test = to_categorical(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall, f1 score 함수\n",
    "\n",
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    precision = precision_metric(y_true, y_pred)\n",
    "    recall = recall_metric(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 특정 snr일때 (18, 0, -8) 평가를 확인하기 위한 setting\n",
    "\n",
    "test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "test_X_i = x_test[np.where(np.array(test_SNRs)==18)] #==18이 default.\n",
    "test_Y_i = y_test[np.where(np.array(test_SNRs)==18)] #==18이 default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network 설정\n",
    "print(\"Network starting...\")\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(128,2)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Conv1D(filters=80, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=[\"accuracy\", precision_metric, recall_metric, f1_metric])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=1024, epochs=1, verbose=1) # 1 epoch 만\n",
    "\n",
    "loss, accuracy, precision, recall, f1 = model.evaluate(test_X_i, test_Y_i, verbose=1, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, precision, recall, f1 score 값 출력\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusision matrix 함수,아래 링크 참고함\n",
    "\n",
    "#https://github.com/radioML/examples/blob/master/modulation_recognition/RML2016.10a_VTCNN2_example.ipynb\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr -20부터 18까지의 정확도 출력,아래 링크 참고함\n",
    " #https://github.com/radioML/examples/blob/master/modulation_recognition/RML2016.10a_VTCNN2_example.ipynb\n",
    "\n",
    "\n",
    "acc = {}\n",
    "for snr in snrs:\n",
    "\n",
    "    # extract classes @ SNR\n",
    "    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "    test_X_i = x_test[np.where(np.array(test_SNRs)==snr)]\n",
    "    test_Y_i = y_test[np.where(np.array(test_SNRs)==snr)]\n",
    "    \n",
    "    test_Y_i_hat = model.predict(test_X_i)\n",
    "    conf = np.zeros([11,11])\n",
    "    confnorm = np.zeros([11,11])\n",
    "    for i in range(0,test_X_i.shape[0]):\n",
    "        j = list(test_Y_i[i,:]).index(1)\n",
    "        k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "        conf[j,k] = conf[j,k] + 1\n",
    "    for i in range(0,11):\n",
    "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confnorm, labels=mods, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "    \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    print(\"Accuracy:\", cor / (cor+ncor))\n",
    "    acc[snr] = 1.0*cor/(cor+ncor)\n",
    "\n",
    " # 해당 선택한 vector의 snr 종합 정확도 출력\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(snrs, list(map(lambda x: acc[x], snrs)))\n",
    "plt.xlabel(\"Signal to Noise Ratio\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Classification Accuracy in SNR\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
